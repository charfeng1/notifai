# CLAUDE.md - 基准测试指南

本文件为 Claude Code 提供基准测试的格式化指南。

## 📋 基准测试流程

### 1. 创建基准测试目录
```bash
benchmarks/
├── 001-baseline-<model-name>/
├── 002-baseline-<model-name>/
├── 003-finetune-<model-name>-<version>/
└── MODEL_COMPARISON.md
```

**命名规范:**
- 使用三位数字前缀（001, 002, 003...）
- 类型标识：`baseline`（基线）、`finetune`（微调）、`ablation`（消融）
- 模型名称：小写，使用连字符（例如：`qwen3-0.6b`, `functiongemma-270m`）
- 版本号（可选）：用于微调模型（例如：`v1.0`, `v1.3`）

**示例:**
- `001-baseline-qwen3-0.6b/`
- `002-baseline-functiongemma-270m/`
- `003-finetune-qwen3-0.6b-v1.0/`

### 2. 每个基准测试目录包含

```
001-baseline-qwen3-0.6b/
├── README.md              # 详细分析报告（中文）
├── results.json           # 原始测试结果
└── test_script.py         # 使用的测试脚本
```

## 📝 README.md 格式规范

**重要：所有 README.md 必须使用中文撰写。**

### 必需章节

```markdown
# 基准测试 <编号>: <模型名称>（<训练状态>）

**日期:** YYYY-MM-DD
**模型:** <模型完整名称>
**测试样本:** <样本数量> 个样本
**硬件:** <GPU 型号>

## 测试结果

| 指标 | 分数 |
|------|------|
| **主要指标** | **XX.X%** (数量/总数) |
| 次要指标 | XX.X% (数量/总数) |
| ... | ... |

## 主要发现

### ✓ 优点
- **关键优势 1** - 详细说明
- 其他优势...

### ✗ 缺点
- **主要问题 1** - 详细说明
- 其他问题...

### 错误样本
列出 5-10 个代表性错误案例

## 技术细节

### 模型配置
- 模型路径
- torch.dtype
- device_map
- 推理参数

### 关键实现细节
- 提示词格式
- 特殊处理（如 `/no_think`）
- 已知问题及解决方案

## 幻觉分析（如适用）

**验证结果:** ✓/✗ 描述

详细说明模型是否产生有效集合外的输出

## 与其他模型对比（如适用）

| 指标 | 本模型 | 对比模型 | 差异 |
|------|--------|---------|------|
| ... | ... | ... | ... |

## 结论

**状态:** ✅/❌/⚠️ 描述

总结关键发现和推荐

**下一步:** 明确的行动项
**预期结果:** 明确的目标
```

## 🎯 写作指南

### 语言要求
- **必须使用中文**撰写所有 README.md
- 技术术语可保留英文（如 JSON, GPU, GGUF）
- 代码块和命令保持英文
- 文件名和路径使用英文

### 风格要求
1. **清晰简洁** - 直接陈述事实和发现
2. **数据驱动** - 用数字和百分比支持结论
3. **客观中立** - 避免主观评价，基于测试结果
4. **可操作** - 提供明确的下一步建议

### 使用图标
- ✓ / ✅ - 优点、成功、推荐
- ✗ / ❌ - 缺点、失败、不推荐
- ⚠️ - 警告、需要注意
- ⏭️ - 下一步
- 📊 - 结果、数据
- 🎯 - 目标、重点

### 关键指标标准

**必须报告的指标:**
1. 主要任务准确率（如文件夹分类准确率）
2. 次要任务准确率（如优先级分类准确率）
3. 解析失败率
4. 幻觉率（如适用）
5. 资源占用（显存、推理时间）

**阈值定义:**
- ✅ 生产环境就绪: ≥80% 准确率，0% 幻觉
- ⚠️ 需要改进: 50-80% 准确率
- ❌ 不可用: <50% 准确率或 >10% 幻觉率

## 🔍 幻觉检测

**重要：每个基线测试必须包含幻觉分析**

使用验证脚本检查模型输出是否在有效集合内：

```python
# 定义有效集合
VALID_FOLDERS = {"Work", "Personal", "Promotions", "Alerts"}
VALID_PRIORITIES = {1, 2, 3, 4, 5}

# 检查每个预测
for prediction in predictions:
    if prediction not in VALID_SET:
        # 记录为幻觉
        hallucinations.append(prediction)
```

**报告格式:**
```markdown
## 幻觉分析

**验证结果:** ✓ 零幻觉（0/100 样本）/ ✗ 存在幻觉（X/100 样本）

模型预测了有效集合之外的值：
- 列出所有幻觉案例
- 说明预期值

**影响:**
- 生产环境安全性评估
- 是否需要 GBNF 语法约束
```

## 📊 MODEL_COMPARISON.md 格式

在 `benchmarks/MODEL_COMPARISON.md` 中维护总体对比：

```markdown
# 模型基线对比总结

## 快速对比

| 模型 | 主要指标 | 次要指标 | 幻觉率 | 显存 | 推荐 |
|------|---------|---------|--------|------|------|
| 模型1 | XX% | XX% | X% | X.X GB | ✅/❌ |
| 模型2 | XX% | XX% | X% | X.X GB | ✅/❌ |

## 详细分析
（每个模型的详细章节）

## 推荐方案
（基于测试结果的明确推荐）

## 下一步行动
（优先级排序的行动项）
```

## 🚫 避免事项

1. ❌ 使用英文撰写分析（除技术术语外）
2. ❌ 主观评价无数据支持（"我觉得..."）
3. ❌ 缺少幻觉分析
4. ❌ 不明确的结论（"可能需要..."）
5. ❌ 缺少可操作的下一步

## ✅ 良好实践

1. ✓ 所有陈述基于实测数据
2. ✓ 包含代表性错误样本
3. ✓ 明确标注推荐/不推荐
4. ✓ 提供完整的技术配置信息
5. ✓ 验证并报告幻觉情况

## 示例文件

参考现有基准测试：
- `001-baseline-qwen3-0.6b/README.md` - 优秀示例
- `002-baseline-functiongemma-270m/README.md` - 包含幻觉分析
- `MODEL_COMPARISON.md` - 对比总结

## 更新日志

**2026-01-07:** 初始版本
- 定义基准测试目录结构
- 规定中文写作要求
- 强制幻觉检测
